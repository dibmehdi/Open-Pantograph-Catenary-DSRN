# -*- coding: utf-8 -*-
"""Increment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aS8Ex8SKIEF7-l6-xXzVcs75Q-EuoY-a
"""

import cv2
import time
from tqdm import tqdm

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Video paths on Google Drive
input_video_path = '/content/drive/MyDrive/Combined_Video/13 AL_combined.mp4'
output_video_path = '/content/drive/MyDrive/Combined_Video/13_AL_combined_with_overlay1.mp4'

# OpenCV video capture from Google Drive
cap = cv2.VideoCapture(input_video_path)
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
input_fps = int(cap.get(cv2.CAP_PROP_FPS))
output_fps = 24
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# Define the codec and create VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter(output_video_path, fourcc, output_fps, (frame_width, frame_height))

# Starting and ending points for the video and incrementing number
start_point = 9.242
end_point = 68.32

# Additional reference point at 18 minutes and 18 seconds
reference_time = 9 * 60 + 46  # in seconds
reference_point = 34.27

# Read the first frame to get dimensions
ret, prev_frame = cap.read()
height, width, _ = prev_frame.shape

# Variables for timing and incrementing
current_point = start_point
frame_duration = 1 / input_fps

# Process video frames
for frame_idx in tqdm(range(total_frames), desc="Processing Frames"):
    ret, current_frame = cap.read()
    if not ret:
        break

    # Convert frames to grayscale
    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
    current_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)

    # Calculate frame difference
    frame_diff = cv2.absdiff(current_gray, prev_gray)
    diff_intensity = cv2.sumElems(frame_diff)[0] / (frame_diff.shape[0] * frame_diff.shape[1])

    # If the difference intensity is above a threshold, consider it a significant movement
    if diff_intensity > 10:  # You can adjust the threshold as needed
        # Calculate the current point based on video progress
        elapsed_time = frame_idx / input_fps
        current_point = start_point + ((end_point - start_point) * elapsed_time / (total_frames / input_fps))
        current_point = min(current_point, end_point)

    # Add the reference point at 18 minutes and 18 seconds
    if elapsed_time >= reference_time:
        current_point = reference_point

    # Convert current_point to formatted string (e.g., "00.114")
    current_point_str = f"{current_point:.3f}"

    # Overlay the current point on the frame
    cv2.putText(current_frame, f"PK {current_point_str}", (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)

    # Write the frame to the output video
    out.write(current_frame)

    # Update the previous frame
    prev_frame = current_frame

# Release the video capture, VideoWriter
cap.release()
out.release()
cv2.destroyAllWindows()