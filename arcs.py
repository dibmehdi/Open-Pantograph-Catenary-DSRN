# -*- coding: utf-8 -*-
"""ARCS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HYMaPzC_swzppWAqb9IaM8wYTt1WzqLX
"""

!pip install reportlab

import cv2
import numpy as np
from reportlab.lib.pagesizes import letter
from reportlab.lib import utils
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Image

# Video paths on Google Drive
input_video_path = '/content/drive/MyDrive/Combined_Video/12 AL_combined.mp4'

# OpenCV video capture from Google Drive
cap = cv2.VideoCapture(input_video_path)

# Starting and ending points for the video and incrementing number
start_point = 0.114
end_point = 63.135

# Additional reference points
reference_points = [
    {"time": 23 * 60 + 34, "point": 53.17},   # At 10 minutes and 30 seconds

]


# Read the first frame to get dimensions
ret, prev_frame = cap.read()
input_fps = int(cap.get(cv2.CAP_PROP_FPS))
frame_duration = 1 / input_fps if input_fps > 0 else 0  # Calculate frame duration

# Variables for timing and incrementing
current_point = start_point

# Lists to store frames and their corresponding PK points
detected_frames = []
detected_points = []

# Process video frames
num_found_arcs = 0  # Initialize the count of found arcs

while ret:
    ret, current_frame = cap.read()

    if ret:
        # Convert frames to grayscale
        current_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)

        # Enhance bright regions using thresholding
        _, thresholded_frame = cv2.threshold(current_gray, 200, 255, cv2.THRESH_BINARY)

        # Detect circles (arcs) using HoughCircles on the thresholded frame
        circles = cv2.HoughCircles(
            thresholded_frame,
            cv2.HOUGH_GRADIENT, dp=1, minDist=20, param1=50, param2=30, minRadius=5, maxRadius=100
        )

        # If circles are detected, store the frame and corresponding PK point
        if circles is not None:
            circles = np.uint16(np.around(circles))
            for circle in circles[0, :]:
                detected_frames.append(current_frame.copy())
                detected_points.append(current_point)
                num_found_arcs += 1  # Increment the count of found arcs

        # Calculate the current point based on video progress
        elapsed_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Current elapsed time in seconds
        current_point += ((end_point - start_point) * frame_duration)
        current_point = max(min(current_point, max(start_point, end_point)), min(start_point, end_point))

        # Check for additional reference points
        for ref_point in reference_points:
            if elapsed_time >= ref_point["time"]:
                current_point = ref_point["point"]
    else:
        break  # Break the loop when all frames have been processed

    # Add a delay to slow down processing (adjust the delay value as needed)
    time.sleep(0.1)  # Add a 100ms delay

# Print the number of found arcs
print(f"Number of found arcs: {num_found_arcs}")

# Release the video capture
cap.release()